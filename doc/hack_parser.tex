\section{Interface with the lexer}

The lexer produces a list of tokens (see~\ref{lexer:token_matching}).
The parser save the number of the current token.
Each time a token is matched (\emph{\_eat} method), the current token number is incremented.
This counter does not appear in the generated code. It is handled by the \emph{\_eat} method.

\section{Sequences of subexpressions}

There is nothing particular about sequences (see~\ref{parser:sequences}).
A sequence of expressions is translated into a sequence of Python statements (see~\ref{hack:sequences}).

\section{Alternatives between subexpressions}

Alternatives (see~\ref{parser:alternatives}) are tried in the order of their declaration.
The first match will stop the search.
When a branch fails (i.e. a call to the \emph{\_eat} method raises a \emph{TPGWrongMatch} exception)
the alternative control structure catches the exception and tries the next branch.
On the last branch the exception is not catched in order to be handled by an outer choice point
(see~\ref{hack:alternatives}).

\section{Repetitions}

Repetitions (see~\ref{parser:repetitions}) use the same scheme as alternatives.
The \emph{TPGWrongMatch} exception stops the loop when raised
(see~\ref{hack:repetitions}).

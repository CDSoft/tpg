""" Code generator for TPG parsers


Toy Parser Generator: A Python parser generator
Copyright (C) 2002 Christophe Delord
 
This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

For further information about TPG you can visit
http://christophe.delord.free.fr/en/tpg
"""

from __future__ import generators
import re
import sys

warning = """
#........[ TOY PARSER GENERATOR ].........................!
#                                                        ! !
# Warning: This file was automatically generated by TPG ! | !
# Do not edit this file unless you know what you do.   !  |  !
#                                                     !   @   !
#....................................................!!!!!!!!!!!
#
# For further information about TPG you can visit
# http://christophe.delord.free.fr/en/tpg
"""

_v = 0	# Verbosity level

def setVerbosity(v):
	global _v
	_v = v

def flatten(L):
	""" Flatten a list. Each item is yielded """
	for i in L:
		if type(i) == list:
			for j in flatten(i):
				yield j
		else:
			yield i

def reindent(lines, indent):
	""" Reindent a sequence of lines. Remove common tabs and spaces and add indent tabs """
	def non_blank(l):
		for c in l:
			if c not in ' \t': return 1
	def tabs(l):
		t = 0
		for c in l:
			if c not in ' \t': break
			t += 1
		return t
	t = min([tabs(l) for l in lines if non_blank(l)])
	tab = '\t'*indent
	return [tab+line[t:] for line in lines]

def _if(cond, trueval, falseval):
	""" C-ternary operator like """
	if cond: return trueval
	else   : return falseval

def _p(prec0, prec1):
	""" Add parenthesis according to precedences """
	if prec1 < prec0: return "(%s)"
	return "%s"

class Parsers(list):
	""" List of parsers """

	def __init__(self, opts):
		self.opts = opts

	def add(self, obj):
		""" Add a parser or a code """
		if _v>=1:
			if isinstance(obj, Parser): sys.stdout.write("%s\n"%obj)
		self.append(obj)

	def genCode(self):
		""" Generate code for all parsers """
		code = [
			self.magic(),					# magic line : #!...
			self.warning(),
			self.runtime(),					# runtime if necessary
			[ p.genCode() for p in self ],	# parsers and codes
		]
		code = "\n".join(flatten(code))
		return code

	def magic(self):
		""" Generate the magic line if provided """
		magic = self.opts['magic']
		return _if(magic,"#!%s"%magic,[])
		
	def runtime(self):
		""" Generate the runtime if necessary """
		return [
			'import tpg.base',
		]

	def warning(self):
		return warning.split('\n')

class Options:
	""" Container for TPG options """

	def __init__(self):
		self.opts = {}

	def set(self, opt, val):
		self.opts[opt] = val

	def __getitem__(self, item):
		return self.opts.get(item,None)

class Code:
	""" Container for code sections """

	def __init__(self, code):
		self.code = code

	def __str__(self): return self.code

	def genCode(self, indent=0, vargen=None, p=None):
		return "\n".join(reindent(self.code.splitlines(), indent))

	def collect(self, collector): pass

	def doc(self, prec): return ""

	def empty(self): return 1

def _2str(st):
	return 'r"%s"'%st

class Collector:
	""" Container for token and rule definitions """

	ident_pat = re.compile(r'^\w+$')	# keyword pattern

	def __init__(self):
		self.inline_tokens = []
		self.tokens = []
		self.token_name = {}	# dict: regexp -> token_name
		self.inline_number = 0
		self.rules = []
		self.knowntokens = {}

	def add_inline_token(self, tok):
		""" Add an inline token """
		regexp = tok.expr
		try:
			name = self.token_name[regexp]			# this token has already been stored
		except KeyError:							# if not
			if self.ident_pat.match(regexp):		#	if it is a keyword
				name = regexp						#		the name is the regexp
			else:									#	otherwise
				self.inline_number += 1				#		make a new token name
				name = "_tok_%s"%self.inline_number	#
			self.token_name[regexp] = name			# store the new token name
			self.inline_tokens.append(tok)			# and the new token definition

	def add_token(self, tok):
		""" Add a predefined token """
		self.tokens.append(tok)					# definition
		self.token_name[tok.expr] = tok.tok		# name
		self.knowntokens[tok.tok] = tok			# remember that tok is a token, not a symbol

	def add_rule(self, rule):
		""" Add a rule """
		self.rules.append(rule)

	def __str__(self):
		return "\n".join(map(str,self.inline_tokens+self.tokens))

	def get_inline_tokens(self):
		return	[ (_2str(self.token_name[t.expr]), _2str(t.expr)) for t in self.inline_tokens ]

	def get_tokens(self):
		return [ (_2str(t.tok), _2str(t.expr), t.action, t.sep) for t in self.tokens ]

	def istoken(self, name):
		""" Make the difference between a token and a symbol """
		return name in self.knowntokens

class Parser(list):
	""" Container for a set of rules """

	def __init__(self, name, bases):
		self.name = name		# name of the parser class
		self.bases = bases		# list of the base classes

	def add(self, obj):
		""" Add a token, a rule or a code section """
		if _v>=2: sys.stdout.write("%s\n"%obj)
		self.append(obj)

	def __str__(self): return "%s(%s)"%(self.name, self.bases)

	def genCode(self):
		""" Generate the code of the parser in 2 passes:
			1) get inline token, token and symbol list
			2) generate the code
		"""
		collector = Collector()
		for p in self: p.collect(collector)
		return [
			"class %s(tpg.base.ToyParser,%s):"%(self.name, self.bases.genCode()),
			"",
				self.genInitCode(1, collector.get_inline_tokens(), collector.get_tokens()),
				[ obj.genCode(1) for obj in self ],
		]

	def genInitCode(self, indent, inline_tokens, tokens):
		""" Generate the initialisation code of the scanner """
		tab = "\t"*indent
		tab1 = tab+"\t"
		tab2 = tab1+"\t"
		return [
			tab  +	"def _init_scanner(self):",
			tab1 +		"self._lexer = tpg.base._Scanner(",
			[ tab2 +		"tpg.base._TokenDef(%s, %s),"%t for t in inline_tokens ],
			[ tab2 +		"tpg.base._TokenDef(%s, %s, %s, %s),"%t for t in tokens ],
			tab1 +		")",
			"",
		]

class Object:
	""" Object (identifier or number) container """

	def __init__(self, name):
		self.name = name

	def __str__(self): return self.name

	def genCode(self): return self.name

	def doc(self, prec): return self.name

class String:
	""" String container """

	def __init__(self, name):
		self.name = 'r"%s"'%name;

	def __str__(self): return self.name

	def genCode(self): return self.name

	def doc(self, prec): return self.name

class Objects(list):
	""" Object list container (tuples, arguments, ...) """

	def add(self, obj):
		self.append(obj)

	def __str__(self): return "<%s>"%(','.join(map(str,self)))

	def genCode(self): return "(%s)"%(''.join(['%s, '%o.genCode() for o in self]))

	def doc(self, prec): return _p(prec,self.prec)%("<%s>"%(','.join([o.doc(self.prec) for o in self])))
	prec = 100

class Args(list):
	""" Argument list container (tuples, arguments, ...) """

	def add(self, obj):
		self.append(obj)

	def __str__(self): return ','.join(map(str,self))

	def genCode(self): return ','.join([o.genCode() for o in self])

	def doc(self, prec): return _p(prec,self.prec)%(','.join([o.doc(self.prec) for o in self]))
	prec = 100

class Composition:
	""" Composition container (object.ident) """

	def __init__(self, o1, o2):
		self.o1, self.o2 = o1, o2

	def __str__(self): return "%s.%s"%(self.o1, self.o2)

	def doc(self, prec): return _p(prec,self.prec)%("%s.%s"%(self.o1.doc(self.prec), self.o2.doc(self.prec)))
	prec = 120

	def genCode(self): return "%s.%s"%(self.o1.genCode(), self.o2.genCode())

class Application:
	""" Application container (object<args>) """

	def __init__(self, o, as):
		self.o, self.as = o, as

	def __str__(self):
		return "%s(%s)"%(self.o, ','.join(map(str,self.as)))

	def doc(self, prec):
		return _p(prec,self.prec)%("%s<%s>"%(self.o.doc(self.prec), self.as.doc(self.prec)))
	prec = 120

	def genCode(self): return "%s(%s)"%(self.o.genCode(), self.as.genCode())

class Indexation:
	""" Indexation container (object[index]) """

	def __init__(self, o, i):
		self.o, self.i = o, i

	def __str__(self):
		return "%s[%s]"%(self.o, self.i)

	def doc(self, prec):
		return _p(prec,self.prec)%("%s[%s]"%(self.o.doc(self.prec), self.i.doc(self.prec)))
	prec = 120

	def genCode(self):
		return "%s[%s]"%(self.o.genCode(), self.i.genCode())

class Slice:
	""" Slice container (object:object) """

	def __init__(self, i, j):
		self.i, self.j = i, j

	def __str__(self):
		return "%s:%s"%(self.i, self.j)

	def doc(self, prec):
		if self.i is None: i = ""
		else: i = self.i.doc(self.prec)
		if self.j is None: j = ""
		else: j = self.j.doc(self.prec)
		return _p(prec,self.prec)%("%s:%s"%(i, j))
	prec = 110

	def genCode(self):
		i = self.i and self.i.genCode() or ""
		j = self.j and self.j.genCode() or ""
		return "%s:%s"%(i, j)

class Token:
	""" Token container """

	def __init__(self, tok, expr, fun, sep):
		self.tok = tok			# token
		self.expr = expr		# regular expression
		self.action = fun		# function to apply to the token
		self.sep = sep			# flag telling if tok is a separator

	def __str__(self):
		return "%s %s: '%s' %s"%(self.sep and "separator" or "token", self.tok, self.expr, self.action)

	def collect(self, collector):
		collector.add_token(self)

	def genCode(self, indent):
		return []	# scanner code is generated by Parser

class VariableGenerator:
	""" New variable generator """

	def __init__(self):
		self.variables = {}

	def next(self, base):
		n = self.variables.get(base,0)
		n += 1
		self.variables[base] = n
		return "%s%d"%(base, n)

class Rule:
	""" Rule container """

	def __init__(self, symbol, expr):
		self.symbol = symbol	# head
		self.expr = expr		# body

	def __str__(self):
		return "%s -> %s ;"%(self.symbol, self.expr)

	def collect(self, collector):
		collector.add_rule(self)
		self.expr.collect(collector)

	def genCode(self, indent):
		ret = self.symbol.genRetCode()
		return [
			self.symbol.genDefCode(indent),							# def symbol(args):
			"\t"*(indent+1)+self.doc(self.prec),					#	""" head -> body """
			self.expr.genCode(indent+1,vargen=VariableGenerator()),	#	code
			_if(ret, "\t"*(indent+1)+"return %s"%ret, []),			#	return code
			"",
		]

	def doc(self, prec):
		return '""" %s -> %s """'%(self.symbol.doc(self.prec), self.expr.doc(self.prec))
	prec = 0

class Symbol:
	""" Symbol container """
	
	def __init__(self, id, as, ret):
		self.name = id
		self.args = as
		self.ret = ret

	def __str__(self): return "%s(%s)/%s"%(self.name, ','.join(map(str,self.args)), self.ret)

	def collect(self, collector):
		self.collector = collector

	def genCode(self, indent, vargen=None, p=None):
		""" Code to call a symbol """
		if self.ret: c = "%s = "%self.ret.genCode()
		else: c = ""
		if self.collector.istoken(self.name):
			c += "self._eat('%s')"%self.name
		else:
			c += "self.%s(%s)"%(self.name, self.args.genCode())
		return "\t"*indent + c

	def genDefCode(self, indent):
		""" Code to define a symbol (ie a rule) """
		return "\t"*indent + "def %s(self,%s):"%(self.name, self.args.genCode())

	def genRetCode(self):
		""" Code for the return value of the symbol """
		if self.ret: return self.ret.genCode()
		else: return ""

	def doc(self, prec): return self.name

	def empty(self): return 0

class Sequence(list):
	""" Container for a sequence in a rule """

	def add(self, e):
		self.append(e)

	def __str__(self): return " ".join(map(str,self))

	def collect(self, collector):
		for i in self: i.collect(collector)

	def doc(self, prec): return _p(prec,self.prec)%" ".join([e.doc(self.prec) for e in self if not e.empty()])
	prec = 20

	def genCode(self, indent, vargen=None, p=None):
		return [ e.genCode(indent,vargen=vargen) for e in self ]

	def empty(self):
		for e in self:
			if not e.empty(): return 0
		return 1

class Alternative:
	""" Container for a choice in a rule """

	def __init__(self, a, b):
		self.a = a
		self.b = b

	def __str__(self): return "(%s | %s)"%(self.a, self.b)

	def collect(self, collector):
		self.a.collect(collector)
		self.b.collect(collector)

	def doc(self, prec): return _p(prec,self.prec)%("%s | %s"%(self.a.doc(self.prec), self.b.doc(self.prec)))
	prec = 10

	def genCode(self, indent, vargen=None, p=None):
		tab = "\t"*indent
		if p is None:
			p = vargen.next("__p")
			pos = tab + "%s = self._cur_token"%p
		else:
			pos = []
		return [
			pos,
			tab + "try:",
				self.a.genCode(indent+1,vargen=vargen,p=p),
			tab + "except self.TPGWrongMatch:",
			tab + "\tself._cur_token = %s"%p,
				self.b.genCode(indent+1,vargen=vargen,p=p),
		]

	def empty(self):
		return self.a.empty() and self.b.empty()

class MakeAST:
	""" Container for an AST affectation (LHS=RHS) """

	def __init__(self, LHS, RHS):
		self.LHS = LHS
		self.RHS = RHS

	def __str__(self): return "%s = %s"%(self.LHS, self.RHS)

	def collect(self, collector): pass

	def doc(self, prec): return ""

	def genCode(self, indent, vargen=None, p=None):
		return "\t"*indent + "%s = %s"%(self.LHS.genCode(), self.RHS.genCode())

	def empty(self): return 1

class AddAST:
	""" Container for an AST update (LHS-RHS) """

	def __init__(self, LHS, RHS):
		self.LHS = LHS
		self.RHS = RHS

	def __str__(self): return "%s-%s"%(self.LHS, self.RHS)

	def collect(self, collector): pass

	def doc(self, prec): return ""

	def genCode(self, indent, vargen=None, p=None):
		return "\t"*indent + "%s.add(%s)"%(self.LHS.genCode(), self.RHS.genCode())

	def empty(self): return 1

class Check:
	""" Condition checker """

	def __init__(self, cond):
		self.cond = cond

	def __str__(self): return "check %s"%self.cond

	def collect(self, collector): self.cond.collect(collector)

	def genCode(self, indent, vargen=None, p=None):
		return "\t"*indent + "self.check(%s)"%self.cond.genCode()

	def doc(self, prec): return ""

	def empty(self): return 1

class Rep:
	""" Container for a repeated expression (*, +, ?, {m,n}) """

	def __init__(self, parser, m, M, e):
		if None not in (m, M) and m>M: parser.WrongMatch()
		if e.empty(): parser.WrongMatch()
		self.e = e	# expression
		self.m = m	# min loops
		self.M = M	# max loops

	def __str__(self): return "(%s){%s,%s}"%(self.e, self.m or "", self.M or "")

	def collect(self, collector):
		self.e.collect(collector)

	def doc(self, prec):
		if self.m == 0:
			if self.M == 1:
				r = "?"
			elif self.M is None:
				r = "*"
			else:
				r = "{,%s}"%self.M
		elif self.m == 1:
			if self.M is None:
				r = "+"
			else:
				r = "{1,%s}"%self.M
		else:
			if self.M is None:
				r = "{%s,}"%self.m
			elif self.m == self.M:
				r = "{%s}"%self.m
			else:
				r = "{%s,%s}"%(self.m, self.M)
		return _p(prec,self.prec)%self.e.doc(self.prec) + r
	prec = 30

	def genCode(self, indent, vargen=None, p=None):
		tab = "\t"*indent
		m, M = self.m, self.M
		p = vargen.next("__p")
		if (m, M) == (0, 1):	# "e ?"
			return [
				tab + "%s = self._cur_token"%p,							# get current token
				tab + "try:",
					self.e.genCode(indent+1, vargen=vargen, p=p),		# try to match e once
				tab + "except self.TPGWrongMatch:",						# if failed
				tab + "\tself._cur_token = %s"%p,						# go back to the current token
			]
		elif (m, M) == (0, None):	# "e *"
			return [
				tab + "%s = self._cur_token"%p,							# get current token
				tab + "while 1:",										# loop as much as possible
				tab + "\ttry:",
						self.e.genCode(indent+2, vargen=vargen,p=p),	# try to match e
				tab + "\t\t%s = self._cur_token"%p,						# if succeded get the new current token
				tab + "\texcept self.TPGWrongMatch:",
				tab + "\t\tself._cur_token = %s"%p,						# otherwise go back to the current token
				tab + "\t\tbreak",										# and exit the loop
			]
		else:						# "e +" or "e {m,M}"
			n = vargen.next("__n")
			if m <= 1: p1 = p		# for {0,*} or {1,*}, use the same position variable
			else: p1 = None			# for {2..,*} use a new variable to be able to backtrack on the first
			return [
				tab + "%s = self._cur_token"%p,							# get current token
				tab + "%s = 0"%n,										# loop counter = 0
				tab + "while %s:"%_if(M is None,"1","%s<%s"%(n,M)),		# loop until counter = M
				tab + "\ttry:",
						self.e.genCode(indent+2, vargen=vargen, p=p1),	# try to match e
				tab + "\t\t%s += 1"%n,									# inc loop counter
				tab + "\t\t%s = self._cur_token"%p,						# if succeded get the new current token
				tab + "\texcept self.TPGWrongMatch:",
				_if( m>0,
				[
				tab + "\t\tif %s >= %s:"%(n, m),						# otherwise if enough loops
				tab + "\t\t\tself._cur_token = %s"%p,					# go back to the current token
				tab + "\t\t\tbreak",									# and exit the loop
				tab + "\t\telse:",
				tab + "\t\t\tself.WrongMatch()",						# otherwise fail
				],
				[
				tab + "\t\tself._cur_token = %s"%p,				# go back to the current token
				])
			]

	def empty(self): return self.e.empty()

class InlineToken:
	""" Container for inline tokens """

	def __init__(self, expr, ret):
		self.expr = expr	# expression
		self.ret = ret		# return object

	def __str__(self): return "'%s'/%s"%(self.expr, self.ret)

	def collect(self, collector):
		collector.add_inline_token(self)
		self.collector = collector

	def genCode(self, indent, vargen=None, p=None):
		if self.ret:
			ret = "%s = "%self.ret.genCode()
		else:
			ret = ""
		name = self.collector.token_name[self.expr]
		if not self.expr.startswith(name):
			comment = " # %s"%self.expr
		else:
			comment = ""
		return "\t"*indent + ret + "self._eat('%s')%s"%(name, comment)

	def doc(self, prec): return "'%s'"%self.expr

	def empty(self): return 0

class Mark:
	""" Container for marks """

	def __init__(self, obj):
		self.obj = obj;

	def __str__(self): return "!%s"%self.obj

	def collect(self, collector): pass

	def genCode(self, indent, vargen=None, p=None):
		return "\t"*indent + "%s = self._mark()"%self.obj.genCode()

	def doc(self, prec): return ""

	def empty(self): return 1

class Extraction:
	""" Container for text extraction """

	def __init__(self, start, end):
		self.start = start
		self.end = end

	def __str__(self): return "%s..%s"%(self.start, self.end)

	def collect(self, collector): pass

	def genCode(self, vargen=None, p=None):
		return "self._extract(%s,%s)"%(self.start.genCode(), self.end.genCode())

	def doc(self, prec): return ""

	def empty(self): return 1


#!/usr/bin/env python2.2

#........[ TOY PARSER GENERATOR ].........................!
#                                                        ! !
# Warning: This file was automatically generated by TPG ! | !
# Do not edit this file unless you know what you do.   !  |  !
#                                                     !   @   !
#....................................................!!!!!!!!!!!
#
# For further information about TPG you can visit
# http://christophe.delord.free.fr/en/tpg


from __future__ import generators
import re


class _TokenDef:

	ident_pat = re.compile(r'^\w+$')
	
	def __init__(self, tok, regex=None, action=None, separator=0):
		if regex is None: regex = tok
		if self.ident_pat.match(regex): regex += r'\b'
		if action is None: action = lambda x:x
		elif not callable(action): action = lambda x,y=action:y
		self.tok = tok
		self.regex = '(?P<%s>%s)'%(tok, regex)
		self.action = action
		self.separator = separator

	def __str__(self):
		return "token %s: %s %s;"%(self.tok, self.regex, self.action)

class _Token:

	def __init__(self, tok, text, val, lineno, start, end):
		self.tok = tok
		self.text = text
		self.val = val
		self.lineno = lineno
		self.start = start
		self.end = end

	def __str__(self):
		return "%d:%s[%s]"%(self.lineno, self.tok, self.val)

class _Eof:

	def __init__(self, lineno='EOF'):
		self.lineno = lineno
		self.text = 'EOF'
		self.val = 'EOF'

	def __str__(self):
		return "%s:Eof"%self.lineno

class _Scanner:

	def __init__(self, *tokens):
		regex = []
		actions = {}
		separator = {}
		for token in tokens:
			regex.append(token.regex)
			actions[token.tok] = token.action
			separator[token.tok] = token.separator
		self.regex = re.compile('|'.join(regex))
		self.actions = actions
		self.separator = separator

	def tokens(self, input):
		self.input = input
		i = 0
		l = len(input)
		lineno = 1
		toks = []
		while i<l:
			token = self.regex.match(input,i)
			if not token:
				last = toks and toks[-1] or _Eof(lineno)
				raise LexicalError(last)
			j = token.end()
			for (t,v) in token.groupdict().items():
				if v is not None and self.actions.has_key(t):
					tok = t
					text = token.group()
					val = self.actions[tok](text)
					break
			if not self.separator[tok]: toks.append(_Token(tok, text, val, lineno, i, j))
			lineno += input.count('\n', i, j)
			i = j
		return toks

class TPGWrongMatch(Exception):
	def __init__(self, last):
		self.last = last

class LexicalError(Exception):
	def __init__(self, last):
		self.last = last
	def __str__(self):
		if self.last:
			return "%s: Lexical error near %s"%(self.last.lineno, self.last.text)
		else:
			return "1: Lexical error"

class SyntaxError(Exception):
	def __init__(self, last):
		self.last = last
	def __str__(self):
		if self.last:
			return "%s: Syntax error near %s"%(self.last.lineno, self.last.text)
		else:
			return "1: Syntax error"

class ToyParser:

	def _init_scanner(self, *tokens):
		self._lexer = _Scanner(*[_TokenDef(*t) for t in tokens])
		self._cur_token = 0

	def _eat(self, token):
		try:
			t = self._tokens[self._cur_token]
		except IndexError:
			self.WrongMatch()
		if t.tok == token:
			self._cur_token += 1
			return t.val
		else:
			self.WrongMatch()

	def WrongMatch(self):
		try:
			raise TPGWrongMatch(self._tokens[self._cur_token])
		except IndexError:
			raise TPGWrongMatch(_Eof())

	def __call__(self, input, *args):
		return self.parse('START', input, *args)

	def parse(self, symbol, input, *args):
		try:
			self._tokens = self._lexer.tokens(input)
			self._cur_token = 0
			ret = getattr(self, symbol)(*args)
			if self._cur_token < len(self._tokens):
				self.WrongMatch()
			return ret
		except TPGWrongMatch, e:
			raise SyntaxError(e.last)

	def _mark(self):
		return self._cur_token

	def _extract(self, a, b):
		if not self._tokens: return ""
		if a<len(self._tokens):
			start = self._tokens[a].start
		else:
			start = self._tokens[-1].end
		if b>0:
			end = self._tokens[b-1].end
		else:
			end = self._tokens[0].start
		return self._lexer.input[start:end]

	def lineno(self, mark=None):
		if mark is None: mark = self._cur_token
		if not self._tokens: return 0
		if mark<len(self._tokens):
			return self._tokens[mark].start
		else:
			return self._tokens[-1].end
	


from string import atoi, atof, atol
from math import sqrt, cos, sin, tan, acos, asin, atan
class Calc(ToyParser,dict):

	def __init__(self):
		self._init_scanner(
			(r"vars", r"vars"),
			(r"_tok_1", r"="),
			(r"_tok_2", r"\("),
			(r"_tok_3", r"\)"),
			(r"_tok_4", r","),
			(r"space", r"(\s|\n)+", None, 1),
			(r"pow_op", r"\^|\*\*", self.make_op, 0),
			(r"add_op", r"[+-]", self.make_op, 0),
			(r"mul_op", r"[*/%]", self.make_op, 0),
			(r"funct1", r"(cos|sin|tan|acos|asin|atan|sqr|sqrt|abs)\b", self.make_op, 0),
			(r"funct2", r"(norm)\b", self.make_op, 0),
			(r"real", r"(\d+\.\d*|\d*\.\d+)([eE][-+]?\d+)?|\d+[eE][-+]?\d+", atof, 0),
			(r"integer", r"\d+", atol, 0),
			(r"VarId", r"[a-zA-Z_]\w*", None, 0),
		)

	
	def mem(self):
		vars = self.items()
		vars.sort()
		return "\n\t" + "\n\t".join([ "%s = %s"%(var, val) for (var, val) in vars ])
	
	def make_op(self, op):
		return {
			'+'   : (lambda x,y:x+y),
			'-'   : (lambda x,y:x-y),
			'*'   : (lambda x,y:x*y),
			'/'   : (lambda x,y:x/y),
			'^'   : (lambda x,y:x**y),
			'**'  : (lambda x,y:x**y),
			'cos' : cos,
			'sin' : sin,
			'tan' : tan,
			'acos': acos,
			'asin': asin,
			'atan': atan,
			'sqr' : (lambda x:x*x),
			'sqrt': sqrt,
			'abs' : abs,
			'norm': (lambda x,y:sqrt(x*x+y*y)),
		}[op]
	def START(self,):
		""" START -> 'vars'  | VarId '=' Expr  | Expr """
		__p1 = self._cur_token
		try:
			try:
				self._eat('vars')
				e = self.mem()
			except TPGWrongMatch:
				self._cur_token = __p1
				v = self._eat('VarId')
				self._eat('_tok_1') # =
				e = self.Expr()
				self[v] = e
		except TPGWrongMatch:
			self._cur_token = __p1
			e = self.Expr()
		return e

	def Var(self,):
		""" Var -> VarId """
		v = self._eat('VarId')
		return self.get(v,0)

	def Expr(self,):
		""" Expr -> Term (add_op Term )* """
		e = self.Term()
		__p1 = self._cur_token
		while 1:
			try:
				op = self._eat('add_op')
				t = self.Term()
				e = op(e,t)
				__p1 = self._cur_token
			except TPGWrongMatch:
				self._cur_token = __p1
				break
		return e

	def Term(self,):
		""" Term -> Fact (mul_op Fact )* """
		t = self.Fact()
		__p1 = self._cur_token
		while 1:
			try:
				op = self._eat('mul_op')
				f = self.Fact()
				t = op(t,f)
				__p1 = self._cur_token
			except TPGWrongMatch:
				self._cur_token = __p1
				break
		return t

	def Fact(self,):
		""" Fact -> add_op Fact  | Pow """
		__p1 = self._cur_token
		try:
			op = self._eat('add_op')
			f = self.Fact()
			f = op(0,f)
		except TPGWrongMatch:
			self._cur_token = __p1
			f = self.Pow()
		return f

	def Pow(self,):
		""" Pow -> Atom (pow_op Fact )? """
		f = self.Atom()
		__p1 = self._cur_token
		try:
			op = self._eat('pow_op')
			e = self.Fact()
			f = op(f,e)
		except TPGWrongMatch:
			self._cur_token = __p1
		return f

	def Atom(self,):
		""" Atom -> real | integer | Function | Var | '\(' Expr '\)' """
		__p1 = self._cur_token
		try:
			try:
				try:
					try:
						a = self._eat('real')
					except TPGWrongMatch:
						self._cur_token = __p1
						a = self._eat('integer')
				except TPGWrongMatch:
					self._cur_token = __p1
					a = self.Function()
			except TPGWrongMatch:
				self._cur_token = __p1
				a = self.Var()
		except TPGWrongMatch:
			self._cur_token = __p1
			self._eat('_tok_2') # \(
			a = self.Expr()
			self._eat('_tok_3') # \)
		return a

	def Function(self,):
		""" Function -> funct1 '\(' Expr '\)'  | funct2 '\(' Expr ',' Expr '\)'  """
		__p1 = self._cur_token
		try:
			f = self._eat('funct1')
			self._eat('_tok_2') # \(
			x = self.Expr()
			self._eat('_tok_3') # \)
			y = f(x)
		except TPGWrongMatch:
			self._cur_token = __p1
			f = self._eat('funct2')
			self._eat('_tok_2') # \(
			x1 = self.Expr()
			self._eat('_tok_4') # ,
			x2 = self.Expr()
			self._eat('_tok_3') # \)
			y = f(x,y)
		return y


calc = Calc()
while 1:
	l = raw_input("\n:")
	if l:
		try:
			print calc(l)
		except (SyntaxError, LexicalError), e:
			print e
		except ZeroDivisionError:
			print "Zero Division Error"
		except OverflowError:
			print "Overflow Error"
	else:
		break